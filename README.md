# Emoji Picker with Emotion Verification

A web application that uses facial expression detection to verify whether a user's actual emotion matches the emoji they select. Features both Python backend (using OpenCV and DeepFace) and JavaScript frontend for maximum accuracy.

Basic Details
Team Name: QWERTY

Team Members
 * Team Lead: Muhammad Nasih N - GECI
 * Member 2: Abhiraj Krishna - GECI

Project Description
An over-engineered web application that uses your webcam to see if you're faking your emotions. It cross-references your real-time facial expression with the emoji you select, ensuring complete emotional transparency whether you want it or not.
The Problem (that doesn't exist)
In today's digital world, emoji fraud is rampant. People send a smiley face üôÇ while feeling dead inside, or an angry face üò† when they're just mildly annoyed. We're tackling the global crisis of emotional inauthenticity by forcing users to prove they genuinely feel the emoji they send.
The Solution (that nobody asked for)
We present the Emoji Picker with Emotion Verification! This revolutionary tool uses not one, but two complex facial recognition systems to call you out on your emotional dishonesty. Simply pick an emoji, make the face, and our state-of-the-art "Truth-o-Meter" will tell you if you're a "Great match" or a dirty liar ("‚ùå Mismatch").
Technical Details
Technologies/Components Used
For Software:
 * Languages used: Python, JavaScript, HTML5, CSS3
 * Frameworks used:
   * Backend: Flask
   * Frontend: TensorFlow.js
 * Libraries used:
   * Python: OpenCV, DeepFace, TensorFlow
   * JavaScript: MediaPipe Face Mesh
 * Tools used: WebRTC, RESTful API
For Hardware:
 * List main components: A standard webcam
 * List specifications: Any modern webcam supported by your browser
 * List tools required: A computer with a web browser
Implementation
For Software:
Installation
# Recommended: Run the setup script
python3 setup.py

# Or install manually
pip3 install -r requirements.txt

Run
# Use the startup script (Linux/Mac)
./start_emotion_detector.sh

# Or start manually
python3 emotion_detector.py
# Then open index.html in your browser

Project Documentation
For Software:
Screenshots
![Screenshot1](Add screenshot 1 here with proper name)
Caption: The main user interface with the camera feed active and emoji selection panel.
![Screenshot2](Add screenshot 2 here with proper name)
Caption: A "‚úÖ Great match" verification result after the user successfully matches their expression to the 'Happy' emoji.
![Screenshot3](Add screenshot 3 here with proper name)
Caption: A "‚ùå Mismatch" result, indicating the user's expression does not align with the selected emoji.
Diagrams
![Workflow](Add your workflow/architecture diagram here)
Caption: The application's architecture. The frontend first attempts to communicate with the Python Flask backend via a REST API for high-accuracy emotion detection. If the backend is unavailable, it automatically falls back to the in-browser TensorFlow.js model for processing.
For Hardware:
This is a software-based project, so hardware schematics and build photos are not applicable.
Schematic & Circuit
![Circuit](Add your circuit diagram here)
Caption: N/A
![Schematic](Add your schematic diagram here)
Caption: N/A
Build Photos
![Components](Add photo of your components here)
Caption: N/A
![Build](Add photos of build process here)
Caption: N/A
![Final](Add photo of final product here)
Caption: N/A
Project Demo
Video
[Add your demo video link here]
Explain what the video demonstrates: The video shows a user starting the application, selecting different emojis (Happy, Sad, Angry), and modifying their facial expression to match. It demonstrates successful verifications, low confidence warnings, and mismatch errors.
Additional Demos
[Add any extra demo materials/links]
Team Contributions
 * Muhammad Nasih N :  Devolpment & Implementation
 * Abhiraj Krishna : Documentation , Presentation & Concept Design


Made with ‚ù§Ô∏è at TinkerHub Useless Projects
